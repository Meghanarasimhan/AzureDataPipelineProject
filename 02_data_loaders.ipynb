{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323ace37-0ff6-4433-b0a6-38c6dc42a7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading module initialized\nCache setting: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING MODULE - Load Olympic Datasets from Azure Storage\n",
    "# =============================================================================\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append('/Workspace/Users/pmanoj@depaul.edu')\n",
    "from config import config\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Data loading module initialized\")\n",
    "print(f\"Cache setting: {config.CACHE_DATAFRAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9d3b84-2870-473b-a57c-30ab5835c888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:Spark config set successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Storage Configurations \n",
    "storage_account_name = \"tokyoolympicdatamegha\"\n",
    "container_name = \"tokyo-olympic-data\"\n",
    "access_key = \"55fIbG8NXjwmjgmXr8GsN6c5A+PQc3pI4ZQdKjUg/VOTPkpRpzvU8OHrp59KF5eA9pEKAHr6cdgi+AStH+5DOw==\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", \n",
    "    access_key)\n",
    "\n",
    "logger.info(\"Spark config set successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1baab142-62dd-4fbc-a9e1-9d64a37ca6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:Loading datasets from Azure blob storage...\nINFO:__main__:Base path: wasbs://tokyo-olympic-data@tokyoolympicdatamegha.blob.core.windows.net/raw/\nINFO:__main__:Datasets Cached for Performance\nINFO:__main__:Datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def load_olympic_datasets():\n",
    "    \"\"\"\n",
    "    Load all Olympic datasets from Azure blob storage.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all DataFrames: athletes_df, medals_df, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Loading datasets from Azure blob storage...\")\n",
    "\n",
    "        storage_account_name = \"tokyoolympicdatamegha\"\n",
    "        container_name = \"tokyo-olympic-data\"\n",
    "        base_path = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/raw/\"\n",
    "        \n",
    "\n",
    "        #Load Datasets\n",
    "        athletes_df = spark.read.csv(f\"{base_path}Atheletes\", header=True, inferSchema=True)\n",
    "        coaches_df = spark.read.csv(f\"{base_path}Coaches\", header=True, inferSchema=True)\n",
    "        gender_df = spark.read.csv(f\"{base_path}GenderEntriesData\", header=True, inferSchema=True)\n",
    "        medals_df = spark.read.csv(f\"{base_path}Medals\", header=True, inferSchema=True)\n",
    "        teams_df = spark.read.csv(f\"{base_path}Teams\", header=True, inferSchema=True)\n",
    "\n",
    "        #Caching DataFrames\n",
    "        if config.CACHE_DATAFRAMES:\n",
    "            athletes_df.cache()\n",
    "            coaches_df.cache()\n",
    "            gender_df.cache()\n",
    "            medals_df.cache()\n",
    "            teams_df.cache()\n",
    "        \n",
    "        logger.info(\"Datasets Cached for Performance\")\n",
    "\n",
    "        #verify DataFrames\n",
    "        assert athletes_df.count() > 0, \"Athletes DataFrame is empty\"\n",
    "        assert coaches_df.count() > 0, \"Coaches DataFrame is empty\"\n",
    "        assert gender_df.count() > 0, \"Gender DataFrame is empty\"\n",
    "        assert medals_df.count() > 0, \"Medals DataFrame is empty\"\n",
    "        assert teams_df.count() > 0, \"Teams DataFrame is empty\"\n",
    "\n",
    "        return athletes_df, coaches_df, gender_df, medals_df, teams_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading datasets: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load datasets\n",
    "athletes_df, coaches_df, gender_df, medals_df, teams_df = load_olympic_datasets()\n",
    "\n",
    "logger.info(\"Datasets loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_data_loaders",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}