{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e184de-6c24-451d-8f3a-666b82902ada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Workspace/Users/pmanoj@depaul.edu')\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bfbf555-4154-4b86-bf34-a7bc5224abc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./06_master_analytics_transformation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8988436c-6894-44bd-8348-db3c58c2d0ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def export_to_power_bi(master_datasets):\n",
    "    \"\"\"\n",
    "    Export datasets in Power BI friendly format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting Power BI export...\")\n",
    "        storage_account_name = \"tokyoolympicdatamegha\"\n",
    "        access_key = \"\"\n",
    "\n",
    "        spark.conf.set(\n",
    "            f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",\n",
    "            access_key\n",
    "        )\n",
    "        output_path = \"wasbs://tokyo-olympic-data@tokyoolympicdatamegha.blob.core.windows.net/transformed/power_bi_exports/\"\n",
    "        \n",
    "        dbutils.fs.mkdirs(output_path)\n",
    "        logger.info(f\"Created output directory: {output_path}\")\n",
    "\n",
    "        exported_files = []\n",
    "\n",
    "        for dataset_name, df in master_datasets.items():\n",
    "            export_path = f\"{output_path}{dataset_name}.csv\"\n",
    "            \n",
    "            df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(export_path)\n",
    "            \n",
    "            logger.info(f\"Exported {dataset_name}: {df.count()} rows to {export_path}\")\n",
    "            exported_files.append(export_path)\n",
    "\n",
    "        summary_info = spark.createDataFrame([\n",
    "            (\"country_analytics\", \"Country-level performance metrics and strategic insights\"),\n",
    "            (\"sport_analytics\", \"Sport-level gender balance and competition analysis\"), \n",
    "            (\"executive_summary\", \"High-level KPIs and overall Olympic performance\"),\n",
    "            (\"medal_efficiency\", \"Medal efficiency analysis by country\"),\n",
    "            (\"sport_dominance\", \"Sport concentration and specialization strategies\"),\n",
    "            (\"gender_analysis\", \"Gender participation and opportunity analysis\")\n",
    "        ], [\"dataset_name\", \"description\"])\n",
    "\n",
    "        summary_path = f\"{output_path}dataset_guide.csv\"\n",
    "        summary_info.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(summary_path)\n",
    "        \n",
    "        logger.info(\"Power BI export completed successfully\")\n",
    "        return exported_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Power BI export failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "print(\"Power BI export functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dec65567-4211-4af4-8f92-b52ddbf9e528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"EXECUTING POWER BI EXPORT PIPELINE\")\n",
    "    \n",
    "    logger.info(\"Generating master analytics datasets...\")\n",
    "    master_data = create_master_analytics(athletes_df, medals_df, gender_df, config)\n",
    "    \n",
    "    exported_files = export_to_power_bi(master_data)\n",
    "    \n",
    "    print(\"POWER BI EXPORT COMPLETED\")\n",
    "    print(f\"Exported {len(exported_files)} datasets\")\n",
    "    print(\"\\nDatasets ready for Power BI:\")\n",
    "    \n",
    "    for i, file_path in enumerate(exported_files, 1):\n",
    "        print(f\"{i}. {file_path}\")\n",
    "    \n",
    "    print(f\"\\n NEXT STEPS \")\n",
    "    print(\"1. Download the CSV files from storage or use link to storage\")\n",
    "    print(\"2. Open Power BI Desktop\")\n",
    "    print(\"3. Import the CSV files\")\n",
    "    print(\"4. Create relationships between tables\")\n",
    "    print(\"5. Build your Olympic analytics dashboard!\")\n",
    "    \n",
    "    logger.info(\"Power BI export pipeline completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Export pipeline failed: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_power_bi_export",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
